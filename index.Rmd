---
title: "BS in science"
author: "Rick O. Gilmore"
bibliography: bib/psu-repro.bib
csl: bib/apa.csl
date: "`r Sys.time()`"
css: 
  - css/ioslides.css
  - css/scrolling.css
output: 
  ioslides_presentation:
    self_contained: false
    widescreen: true
    lib_dir: libs
    incremental: false
    transition: default
---

```{r setup, include=FALSE}

require("DiagrammeR")

knitr::opts_chunk$set(echo = FALSE,
                      fig.align = "center")
```

<!-- Scrolling final reference page -->
<!-- http://stackoverflow.com/q/38260799 -->
<style>
slides > slide { overflow: scroll; }
slides > slide:not(.nobackground):before {
  background: none;
  }
slides > slide:not(.nobackground):after {
  content: '';
  background: none;
  }
}
</style>

# Preliminaries

## About me

- Professor of Psychology
- Founding Director of Human Imaging, PSU [SLEIC](http://imaging.psu.edu)
- Co-Founder/Co-Director [Databrary.org](http://databrary.org)

---

- B.A. in cognitive science, Brown University
- Ph.D. in cognitive neuroscience, Carnegie Mellon University
- vision, perception & action, brain development, open science
- ham (K3ROG), actor/singer, banjo-picker, hiker/cyclist, coder

## Overview

- Reproducibility in science
- Science and sin
- BS: Beyond sin

# Reproducibility in science

---

```{r}
knitr::include_graphics("img/covid-19.png")
```

<div class="notes">
When scientists share things happen, we all benefit.
Scientists sequenced and openly published the genome of the Covid-19 virus early in 2020.
Vaccines of remarkable success were developed, tested, and deployed with astonishing speed.
Open sharing saved lives.
</div>

---

<iframe width="560" height="315" src="https://www.youtube.com/embed/66oNv_DJuPc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<https://youtu.be/66oNv_DJuPc>

<!-- Data Sharing and Management Snafu in 3 Short Acts (Higher Quality) -->

## What proportion of studies in the published scientific literature are *actually true*?

>- 100%
>- 90%
>- 70%
>- 50%
>- 30%

## How do we define what "*actually true*" means?

## Is there a reproducibility crisis in science?

>- Yes, a significant crisis
>- Yes, a slight crisis
>- No crisis
>- Don't know

---

```{r}
knitr::include_graphics("http://www.nature.com/polopoly_fs/7.36716.1469695923!/image/reproducibility-graphic-online1.jpeg_gen/derivatives/landscape_630/reproducibility-graphic-online1.jpeg")
```

<div class="notes">
Nature conducted a survey of some 1,600 scientists in 2016. They were asked this question and a few others. Here are the results.
</div>

---

```{r, fig.cap="[[@baker_1500_2016]](http://doi.org/10.1038/533452a)", out.width="600px"}
knitr::include_graphics("https://media.springernature.com/w300/springer-static/image/art%3A10.1038%2F533452a/MediaObjects/41586_2016_BF533452a_Fige_HTML.jpg?as=webp")
```

## What does "reproducibility" mean?

- Are we all talking about the same thing?

## *Methods* reproducibility 

- Enough details about materials & methods recorded (& reported) so that
- Can same results with same materials & methods

[[@goodman_what_2016]](http://doi.org/10.1126/scitranslmed.aaf5027)

<div class="notes">
Goodman et al. advocate a new lexicon for reproducibility where...
</div>

---

<div class="centered">
<img src="http://lh6.ggpht.com/_KVa1Tk_k1BU/TTjL-RSY_eI/AAAAAAAABtg/VQIfae1_wtQ/hit_thumb%5B3%5D.jpg?imgmax=800" height=550>
</div>

<div class="notes">
I like to call this the "hit by a truck" scenario.
</div>

## *Results* reproducibility

- Same results from independent study

[[@goodman_what_2016]](http://doi.org/10.1126/scitranslmed.aaf5027)

## *Inferential* reproducibility 

- Same inferences from one or more studies or reanalyses
- Meta- or mega-analyses

[[@goodman_what_2016]](http://doi.org/10.1126/scitranslmed.aaf5027)

## Factors contributing to irreproducible research {.smaller}

```{r, fig.cap="[[@baker_1500_2016]](http://doi.org/10.1038/533452a)"}
knitr::include_graphics("http://www.nature.com/polopoly_fs/7.36719.1464174488!/image/reproducibility-graphic-online4.jpg_gen/derivatives/landscape_630/reproducibility-graphic-online4.jpg")
```

<div class="notes">
These definitions help put some of the presumed causes into perspective.
</div>

## Reproducibility crisis

- Not just psychology and related behavioral sciences
- "Hard" sciences, too
- Challenges affect data collection to statistical analysis to reporting to publishing

---

<div class="centered">
<img src="https://cdn.shopify.com/s/files/1/0877/5762/products/Rigor_Mortis_1024x1024.jpg?v=1491240110" height=550px/>
</div>

<div class="notes">
Clearly, the significant or slight crisis in reproducibility extends across scientific domains. 
Indeed, the NPR science reporter Richard Harris in a book published earlier this year said that sloppy biomedical research creates worthless cures, crushes hope, costs billions.
But rather than cast aspersions on other fields, let me own the sins of my own.
</div>

## Robert Merton and The 'Ethos' of Science

```{r, fig.cap="Wikipedia"}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/en/0/08/Robert_K_Merton.jpg")
```

---

```{r}
knitr::include_graphics("https://www.klinebooks.com/pictures/28217.jpg?v=1428617395")
```

---

- **universalism**: scientific validity is independent of sociopolitical status/personal attributes of its participants
- **communalism**: common ownership of scientific goods (intellectual property)
- **disinterestedness**: scientific institutions benefit a common scientific enterprise, not specific individuals
- **organized skepticism**: claims should be exposed to critical scrutiny before being accepted

## So, is science 'full of it'? {.smaller}

```{r, fig.cap="https://i.pinimg.com/originals/11/99/55/1199557a7cbc80c73dfd6dd58ff19b54.jpg", out.height="500px"}
knitr::include_graphics("https://i.pinimg.com/originals/11/99/55/1199557a7cbc80c73dfd6dd58ff19b54.jpg")
```

<!-- Stepping over bs be like -->

---

- BS persuades, but (knowingly) disregards truth (Frankfurt, [*On Bullshit*](https://en.wikipedia.org/wiki/On_Bullshit))
- Science practices and communications attempt to persuade about the truth
- But if truth value disregarded, overlooked, downplayed, exaggerated...

# Science and sin

---

<div class="centered">
<img src="http://press.princeton.edu/images/k10970.gif" height=550px>
</div>

<div class="notes">
But rather than cast aspersions on other fields, let me focus on my own field's deadly sins, as cognitive neuroscientist Chris Chambers put it.
</div>

## The sin of unreliability {.smaller}

```{r, fig.cap="https://i.reddituploads.com/cfb6336d162f4b908cb6715d3da752b5?fit=max&h=1536&w=1536&s=cb3b9e51ea5fef6fdc229fb24b740b7d"}
knitr::include_graphics("https://i.reddituploads.com/cfb6336d162f4b908cb6715d3da752b5?fit=max&h=1536&w=1536&s=cb3b9e51ea5fef6fdc229fb24b740b7d")
```

---

- There are many ways to be wrong...

## Studies are underpowered {.smaller}

```{r, fig.cap="[[@Szucs2017-fc]](http://dx.doi.org/10.1371/journal.pbio.2000797)", out.width="900px"}
knitr::include_graphics("http://journals.plos.org/plosbiology/article/file?id=10.1371/journal.pbio.2000797.g003&type=large")
```

<div class="notes">
As Szucs and Ioannides have shown based on an analysis of more than 10,000 papers in the cognitive neuroscience literature, sample sizes are small, and the probability of false negatives is high, especially for small to medium effect sizes.
</div>

---

> "*Assuming a realistic range of prior probabilities for null hypotheses, false report probability is likely to exceed 50% for the whole literature.*"
>
> [[@Szucs2017-fc]](http://dx.doi.org/10.1371/journal.pbio.2000797)

- Too often our studies are too small...

<div class="notes">
So, this means that we may not know what we think we know because our studies are too small.
</div>

## The sin of hoarding... {.smaller}

```{r, fig.cap="http://www.clubbinghouse.com/images/photos/covers/20080403153957.jpg"}
knitr::include_graphics("http://www.clubbinghouse.com/images/photos/covers/20080403153957.jpg")
```

<div class="centered">
### ...grants, ...students, ...data
</div>

## Psychologists asked to share data... {.smaller}

```{r, out.height="500px", fig.cap="[[@wicherts_poor_2006]](http://doi.org/10.1037/0003-066X.61.7.726)"}
knitr::include_graphics("https://raw.githubusercontent.com/gilmore-lab/psu-data-repro-bootcamp-2017-07-10/master/img/wicherts_2006_amp_61_7_726_fig1a.jpg")
```

## [[@Vanpaemel2015-zr]](https://doi.org/10.1525/collabra.13)

| Response | Percent |
|----------|---------|
| No reply | 41% |
| Refused/unable to share data | 18% |
| No data despite promise | 4% |
| Data shared after reminder | 16%|
| Data shared after 1st request | 22% |

## The sin of corruptibility... {.smaller}

```{r, fig.cap="[[@lacour_when_2014]](http://doi.org/10.1126/science.1256151)"}
knitr::include_graphics("https://raw.githubusercontent.com/gilmore-lab/psu-data-repro-bootcamp-2017-07-10/master/img/lacour-green.jpg")
```

---

```{r, fig.cap = "http://pubman.mpdl.mpg.de/pubman/item/escidoc:1569964:8/component/escidoc:1569966/Stapel_Investigation_Final_report.pdf"}
knitr::include_graphics("https://raw.githubusercontent.com/gilmore-lab/psu-data-repro-bootcamp-2017-07-10/master/img/flawed-science-stapel.jpg")
```

<div class="notes">
- Stapel was Dean of the School of Social and Behavioral Sciences at Tilburg University, teacher of Scientific Ethics course
- Fraud investigation launched when 3 grad students noticed anomalies -- duplicate entries in data tables
- Stapel confessed, lost position, gave up Ph.D., wrote a book
</div>

---

```{r, fig.cap="http://www.sciencemag.org/news/2012/09/harvard-psychology-researcher-committed-fraud-us-investigation-concludes", out.width="800px"}
knitr::include_graphics("https://raw.githubusercontent.com/gilmore-lab/psu-data-repro-bootcamp-2017-07-10/master/img/hauser-misconduct-science.jpg")
```

<div class="notes">
- Marc Hauser
- Evolutionary/Comparative Psychologist, Professor at Harvard
- Resigned 2011 after internal investigation found him responsible for research misconduct
- Details see [2012 report by NIH Office of Research Integrity (ORI)](https://grants.nih.gov/grants/guide/notice-files/NOT-OD-12-149.html) and [Hauser's response](http://archive.boston.com/whitecoatnotes/2012/09/05/marc-hauser-responds-federal-finding-scientific-misconduct/spzRWEVIPKA4BUu8wi8t8J/story.html). 
</div>

## The sin of bias...

Bem, D.J. (2011). Experimental evidence for anomalous retroactive influences on cognition and affect. *Journal of Personality and Social Psychology*, *100*(3), 407-425.

---

> "*This article reports 9 experiments, involving more than 1,000 participants, that test for retroactive influence by 'time-reversing' well-established psychological effects so that the individual's responses are obtained before the putatively causal stimulus events occur.*"

<div class="notes">
And this 2011 paper by Daryl Bem from Cornell purporting to show evidence for Extrasensory Perception or precognition. Psychology is harder than physics, but it doesn't supercede it. This paper as blogger Tal Yarkoni [notes](http://www.talyarkoni.org/blog/2011/01/10/the-psychology-of-parapsychology-or-why-good-researchers-publishing-good-articles-in-good-journals-can-still-get-it-totally-wrong/) shows the perils of using standard, but flawed research practices.
</div>

---

<div class="centered">
<img src="https://vignette.wikia.nocookie.net/45e9dc22-281b-41a5-93a7-f508a99b8722/scale-to-width-down/627" height=550>
</div>

<div class="notes">
Yes, Bem was arguing for some sort of "Minority Report"-like evidence for precognition or ESP.
</div>
---

> "*We argue that in order to convince a skeptical audience of a controversial claim, one needs to conduct strictly confirmatory studies and analyze the results with statistical tests that are conservative rather than liberal...*" 

[[@Wagenmakers2011-yh]](http://dx.doi.org/10.1037/a0022790)

---

> "*We conclude that Bem's p values do not indicate evidence in favor of precognition; instead, they indicate that experimental psychologists need to change the way they conduct their experiments and analyze their data.*"

[[@Wagenmakers2011-yh]](http://dx.doi.org/10.1037/a0022790)

<div class="notes">
But a careful, post-publication re-evaluation showed that Bem had made a number of small, defensible given current practices, errors that accumulated across his paper. None of them were picked up in review.
</div>

## The sin of hurrying...

```{r, out.height = "500px", fig.cap=="[[@Nuijten2015-ul]](https://doi.org10.3758/s13428-015-0664-2)"}
knitr::include_graphics("img/nuijten-etal.jpg")
```

---

```{r, out.height = "500px", fig.cap="[[@Nuijten2015-ul]](https://doi.org10.3758/s13428-015-0664-2)"}
knitr::include_graphics("https://static-content.springer.com/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig3_HTML.gif")
```

<div class="notes">
Statistical reporting errors in the published literature are more common that many might think.
</div>

## The sin of narrowmindedness...

```{r}
knitr::include_graphics("https://www.rd.com/wp-content/uploads/2017/02/01-How-Bad-is-it-to-Share-a-Toothbrush-159311405-ABykov-760x506.jpg")
```

---

> "*...psychologists tend to treat other peoples’ theories like toothbrushes; no self-respecting individual wants to use anyone else’s.*"
>
> [[@Mischel2011-br]](https://www.psychologicalscience.org/observer/becoming-a-cumulative-science)

---

> "*The toothbrush culture undermines the building of a genuinely cumulative science, encouraging more parallel play and solo game playing, rather than building on each other’s directly relevant best work.*"
>
> [[@Mischel2011-br]](https://www.psychologicalscience.org/observer/becoming-a-cumulative-science)

## The sin of pragmatism...

> "*Reviewers and editors want novel, interesting results. Why would I waste my time doing careful direct replications?*"

> "*Reviewing papers is hard, unpaid work. If I have to check someone's stats, too, I'll quit.*"

-- Any number of researchers I've talked with

---

```{r, fig.cap="https://i.pinimg.com/originals/9b/f4/e5/9bf4e5a1d584bc6065c3e3231f9b3220.gif"}
knitr::include_graphics("https://i.pinimg.com/originals/9b/f4/e5/9bf4e5a1d584bc6065c3e3231f9b3220.gif")
```

<!-- Carrot Stick Psycho Wimp -->

## In our defense...

## Behavior multidimensional

<div class="centered">
<video data-autoplay height="550" controls>
  <source src="https://nyu.databrary.org/slot/27087/0,372193/asset/119877/download?inline=true" type="video/mp4">
Your browser does not support the video tag.
</video>
<small>([Adolph et al., 2016](https://nyu.databrary.org/volume/444))</small>
</div>

## Embedded in nested networks of causal factors

<div class="centered">
<img src="http://3.bp.blogspot.com/-3e_SbLI1Kbc/UkH085O8q5I/AAAAAAAACw4/lAZ_AJdzGss/s1600/bronfenbrenner.jpeg" height=500px>
</div>

---

<div class="centered">
<img src="https://www.researchgate.net/profile/Carlo_Miniussi/publication/269877702/figure/fig2/AS:269128527249411@1441176649721/Hierarchical-modular-organisation-of-the-human-connectome-a-Hubs-regions-with-a.png" height=500px>
</div>

## Humans are diverse

But much (lab-based) data collected are from **W**estern, **E**ducated **I**ndustrialized, **R**ich, **D**emocratic (WEIRD) populations 

<small>[Henrich et al., 2010](http://doi.org/10.1017/S0140525X0999152X)</small>

## Data about humans are sensitive, hard(er) to share

- Must protect participant's identities
- Most protect from harm/embarrassment
- Must anonymize and/or get permission
- Restrictions/controls in academic/biomedical research >> commercial

## Psychology is harder than physics

---

<div class="centered">
<img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/img/psych-harder-1.jpg" width=800px/>
</div>

---

<div class="centered">
<img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-databservatory/master/img/psych-harder-2.jpg" width=800px/>
</div>

# BS: beyond sin

## Beyond sin

- No physics envy, but we can learn from physics and other fields
- Openness and transparency are the means, not the ends
- How do we accelerate, broaden, and deepen discovery?

---

```{r, fig.cap='[[@munafo_manifesto_2017]](http://doi.org/10.1038/s41562-016-0021)', out.width="800px"}
knitr::include_graphics("https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41562-016-0021/MediaObjects/41562_2016_Article_BFs415620160021_Fig1_HTML.jpg?as=webp")
```

<!-- Manifesto for reproducible science -->

<div class="notes">
This recent manifesto from Nature Human Behavior describes the risks to reproducible science at every step of the process.
I urge you to read it.
</div>

## Reproducibility in psychological science

- Bigger samples
- Multiple replications
- Registration
- Data, procedure, and materials sharing
- "Data blinding"
- Larg(er)-scale replication studies

## Reproducibility Project: Psychology (RPP)

[[@collaboration_estimating_2015]](http://science.sciencemag.org/content/349/6251/aac4716)

---

> "*We conducted replications of 100...studies published in three psychology journals using high-powered designs and original materials when available....The mean effect size (r) of the replication effects ...was half the magnitude of the mean effect size of the original effects...*"
> 
> [[@collaboration_estimating_2015]](http://science.sciencemag.org/content/349/6251/aac4716)

---

> "*Ninety-seven percent of original studies had significant results (P < .05). Thirty-six percent of replications had significant results.*"
>
> [[@collaboration_estimating_2015]](http://science.sciencemag.org/content/349/6251/aac4716)

---

> "*39% of effects were subjectively rated to have replicated the original result...*"
>
> [[@collaboration_estimating_2015]](http://science.sciencemag.org/content/349/6251/aac4716)

## [[@Camerer2018-tr]](Camerer2018-tr)

```{r fig.cap='[[@Camerer2018-tr]](Camerer2018-tr)', out.height="500px"}
knitr::include_graphics("https://mfr.osf.io/export?url=https://osf.io/fg4d3/?action=download%26mode=render%26direct%26public_file=True&initialWidth=711&childId=mfrIframe&parentTitle=OSF+%7C+F1+-+EffectSizes.png&parentUrl=https://osf.io/fg4d3/&format=2400x2400.jpeg")
```

---

```{r, fig.cap = '[[@Camerer2018-tr]](Camerer2018-tr)', out.height="500px"}
knitr::include_graphics("https://mfr.osf.io/export?url=https://osf.io/cefq7/?action=download%26mode=render%26direct%26public_file=True&initialWidth=680&childId=mfrIframe&parentTitle=OSF+%7C+F4+-+PeerBeliefs.png&parentUrl=https://osf.io/cefq7/&format=2400x2400.jpeg")
```

## If it's too good to be true, it probably isn't

<https://80000hours.org/psychology-replication-quiz/>

## Video as data and documentation

<div class="centered">
<img src="https://raw.githubusercontent.com/gilmore-lab/sips-2017-video-reproducibility/master/img/gilmore-adolph-nat-hum-beh.jpg" height=550px>
</div>

<div class="notes">
Karen Adolph at NYU is my partner in founding and directing the Databrary project. We have argued that video plays a central role in improving reproducibility in behavioural science. It has uniquely powerful abilities to capture who said or did what when and in what context.
</div>

## Improved statistical practices

- Automated checking of paper statistics (in American Psychological Association formats) via [Statcheck](http://statcheck.io)
- Redefine "statistical significance" as $p<.005$? [(Benjamin et al., 2017)](https://dx.doi.org/10.17605/OSF.IO/MKY9J)
- Or move away from [NHST](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing) toward more robust and cumulative practices (Bayesian, CI/effect-size-driven)     - Better capture what we know or think we know

## Store data, materials, code in repositories

- Data libraries
- Funder, journal mandates for sharing increasing
- But no long-term, stable, funding sources for curation, archiving, sharing

---

```{r, fig.cap="http://cdn2.hubspot.net/hub/134568/file-1208368053-jpg/6-blind-men-hans.jpg", out.height="500px"}
knitr::include_graphics("http://cdn2.hubspot.net/hub/134568/file-1208368053-jpg/6-blind-men-hans.jpg")
```

<div class="notes">
To make the future of big data behavioral science one where we're not just blind men studying our small part of the elephant.
</div>

---

```{r, fig.cap="http://static.neatorama.com/images/2012-09/girl-hugging-elephant.jpg", out.height="500px"}
knitr::include_graphics("http://static.neatorama.com/images/2012-09/girl-hugging-elephant.jpg")
```

<div class="notes">
But where we take off our opaque glasses and embrace the whole glorious animal.
</div>

## Stuff happens {.smaller}

```{r, fig.cap="http://3.bp.blogspot.com/-hcXiVcmcm5g/Tsv1QlO-kUI/AAAAAAAACF0/vT_UjyHwA4k/s1600/manure.jpg", out.height="500px"}
knitr::include_graphics("http://3.bp.blogspot.com/-hcXiVcmcm5g/Tsv1QlO-kUI/AAAAAAAACF0/vT_UjyHwA4k/s1600/manure.jpg")
```

## But science is still a pretty good shovel {.smaller}

```{r, fig.cap="https://www.amazon.com/Shovel-Manure-Other-Lessons-Country-ebook/dp/B004PLNRNC"}
knitr::include_graphics("https://m.media-amazon.com/images/I/51-GFQLf+RL.jpg")
```

---

<div class="centered">

<video width="800" loop data-autoplay>
  <source src="https://github.com/gilmore-lab/DEVSEC-2018/blob/master/mov/databrary-splash.mp4?raw=true" type="video/mp4">
  </video>

rogilmore@psu.edu

<https://gilmore-lab.github.io>

<https://github.com/gilmore-lab/2021-10-19-bs-in-science/>

</div>

## Resources {.smaller}

This talk was produced on `r Sys.Date()` in [RStudio](http://rstudio.com) using R Markdown.
The code and materials used to generate the slides may be found at <https://github.com/gilmore-lab/2021-10-19-bs-in-science/>.
Information about the R Session that produced the code is as follows:

```{r session-info}
sessionInfo()
```

## References {.smaller}